{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a .ktr file to download:\n",
      "1: Get list of tables.ktr\n",
      "2: Process one table.ktr\n",
      "3: save list of all result files.ktr\n",
      "4: set variables.ktr\n",
      "File downloaded and saved to: simplepentaho\\set variables.ktr\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "# GitHub repository details\n",
    "owner = 'Srivalli2024'\n",
    "repo = 'Pentaho_Files_Input'\n",
    "branch = 'main'  # Change this to the desired branch if different\n",
    "\n",
    "# Personal access token (use environment variables or other secure methods to store your token)\n",
    "token = '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'\n",
    "\n",
    "# GitHub API URL to list files in the repository\n",
    "api_url = f'https://api.github.com/repos/{owner}/{repo}/git/trees/{branch}?recursive=1'\n",
    "\n",
    "# Get the list of files in the repository with authentication\n",
    "headers = {'Authorization': f'token {token}'}\n",
    "response = requests.get(api_url, headers=headers)\n",
    "if response.status_code == 200:\n",
    "    files = response.json().get('tree', [])\n",
    "    # Filter for .ktr files\n",
    "    ktr_files = [file['path'] for file in files if file['path'].endswith('.ktr')]\n",
    "    \n",
    "    if ktr_files:\n",
    "        # Display the list of .ktr files to the user\n",
    "        print(\"Select a .ktr file to download:\")\n",
    "        for idx, file in enumerate(ktr_files):\n",
    "            print(f\"{idx + 1}: {file}\")\n",
    "        \n",
    "        # Prompt user to select a file\n",
    "        while True:\n",
    "            try:\n",
    "                selection = int(input(\"Enter the number of the file to download: \")) - 1\n",
    "                if 0 <= selection < len(ktr_files):\n",
    "                    selected_file = ktr_files[selection]\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"Invalid selection. Please try again.\")\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Please enter a number.\")\n",
    "        \n",
    "        # GitHub URL to download the file\n",
    "        download_url = f'https://raw.githubusercontent.com/{owner}/{repo}/{branch}/{selected_file}'\n",
    "        download_response = requests.get(download_url, headers=headers)\n",
    "        \n",
    "        if download_response.status_code == 200:\n",
    "            # Save the file locally\n",
    "            local_file_path = os.path.join('simplepentaho', os.path.basename(selected_file))\n",
    "            with open(local_file_path, 'wb') as f:\n",
    "                f.write(download_response.content)\n",
    "            print(f\"File downloaded and saved to: {local_file_path}\")\n",
    "        else:\n",
    "            print(f\"Failed to download the file. Status code: {download_response.status_code}\")\n",
    "    else:\n",
    "        print(\"No .ktr files found in the repository.\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve the file list. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import openai\n",
    "import os\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "import requests\n",
    "import logging\n",
    "from logging.handlers import RotatingFileHandler\n",
    "\n",
    "# Configure logging with a rotating log file handler\n",
    "log_filename = 'app.log'\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "handler = RotatingFileHandler(log_filename, maxBytes=10*1024*1024, backupCount=1)\n",
    "handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "file_path = None\n",
    "folder_name = None\n",
    "\n",
    "def get_elements_from_file(xml_file_path, element_name):\n",
    "    root = ET.parse(xml_file_path).getroot()\n",
    "    step_elements = root.findall(f'.//{element_name}')\n",
    "    return [ET.tostring(step, encoding='unicode') for step in step_elements] if step_elements else []\n",
    "\n",
    "def save_elements_to_file(input_filename, output_filename):\n",
    "    xml_file_path = f'{input_filename}'\n",
    "    output_text_file_path = f'{output_filename}s.txt' if output_filename == 'step' else 'hop_order.txt'\n",
    "    step_data_strings = get_elements_from_file(xml_file_path, output_filename)\n",
    "\n",
    "    logger.info(f\"{output_filename} elements extracted\")\n",
    "\n",
    "    with open(output_text_file_path, 'w', encoding='utf-8') as output_file:\n",
    "        output_file.writelines(f\"{step_data_string}\\n\" for step_data_string in step_data_strings)\n",
    "\n",
    "    logger.info(f\"The output has been saved to '{output_text_file_path}'\")\n",
    "    print(f\"The output has been saved to '{output_text_file_path}'\")\n",
    "\n",
    "def openai_sequence_steps(hop_order_file_path, steps_file_path):\n",
    "    # Read the configuration file for OpenAI credentials\n",
    "    with open('config_file.json') as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    # Set up OpenAI configuration with the loaded credentials\n",
    "    openai.api_type = json_data[\"openai_api_type\"]\n",
    "    openai.api_base = json_data[\"openai_api_base\"]\n",
    "    openai.api_version = json_data[\"openai_api_version\"]\n",
    "    openai.api_key = json_data['openai_api_key']\n",
    "  \n",
    "    # Read the contents of the steps file\n",
    "    with open(hop_order_file_path, 'r', encoding='utf-8') as file:\n",
    "        hop_order = file.read()\n",
    "        \n",
    "    # Read the contents of the steps file\n",
    "    with open(steps_file_path, 'r', encoding='utf-8') as file:\n",
    "        steps = file.read()\n",
    "  \n",
    "    try:\n",
    "        # Make the API call to OpenAI with the hop info and the contents of steps.txt\n",
    "        response = openai.ChatCompletion.create(\n",
    "            engine=\"gpt-4-32k\",\n",
    "            temperature=0.1,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are an expert in converting Pentaho code to Pyspark code.\\n\\nYou will receive a hop order file and a steps file. Analyze the hop order to determine the sequence, then convert the corresponding steps into Pyspark code following that sequence.\\n\\nReturn the Pyspark code for the entire flow step by step as per the steps file.\\n\\nGive sequence number to each step. Give output in python not in scala\"\n",
    "                },\n",
    "                {   \"role\": \"user\", \n",
    "                    \"content\": f\"Here is the Pentaho hop order file: {hop_order} and the steps file {steps}\"\n",
    "                }\n",
    "            ],\n",
    "        )\n",
    "      \n",
    "        # Extract the output from the response\n",
    "        output = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        return output\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        logger.error(f\"{e}\")\n",
    "        raise\n",
    "\n",
    "def copy_specific_files(source_folder, target_folder, file_names):\n",
    "    if not os.path.exists(target_folder):\n",
    "        os.makedirs(target_folder)\n",
    "    \n",
    "    for file_name in file_names:\n",
    "        source_path = os.path.join(source_folder, file_name)\n",
    "        target_path = os.path.join(target_folder, file_name)\n",
    "        if os.path.exists(source_path):\n",
    "            shutil.copy(source_path, target_path)\n",
    "            print(f\"Copied '{file_name}' to '{target_folder}'.\")\n",
    "        else:\n",
    "            print(f\"File '{file_name}' not found in '{source_folder}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_ktr(file_path, folder_name):\n",
    "        input_filename = file_path\n",
    "        folder_name = os.path.join('spark_code', folder_name)\n",
    "        hop_order_file_path = \"hop_order.txt\"\n",
    "        steps_file_path = \"steps.txt\"\n",
    "        output_file_path = \"pyspark_code.txt\"\n",
    "\n",
    "        save_elements_to_file(input_filename, 'order')\n",
    "        save_elements_to_file(input_filename, 'step')\n",
    "\n",
    "        code_output = openai_sequence_steps(hop_order_file_path, steps_file_path)\n",
    "        print(code_output)\n",
    "\n",
    "        with open(output_file_path, 'a', encoding='utf-8') as output_file:\n",
    "            output_file.write(code_output)\n",
    "\n",
    "        source_folder = \"\"\n",
    "        target_folder = folder_name\n",
    "        file_names = [\"hop_order.txt\", \"steps.txt\", \"pyspark_code.txt\"]\n",
    "        copy_specific_files(source_folder, target_folder, file_names)\n",
    "        for file_name in file_names:\n",
    "            file_path = os.path.join(source_folder, file_name)\n",
    "            os.remove(file_path)\n",
    "        logger.info(f\"The converted code is saved in {folder_name} folder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 14:57:06,409 - INFO - order elements extracted\n",
      "2024-06-11 14:57:06,409 - INFO - The output has been saved to 'hop_order.txt'\n",
      "2024-06-11 14:57:06,409 - INFO - step elements extracted\n",
      "2024-06-11 14:57:06,409 - INFO - The output has been saved to 'steps.txt'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_path is C:\\Multiple_KTR_Updated\\KJB_and_KTR_updated\\simplepentaho\\Process one table.ktr\n",
      "The output has been saved to 'hop_order.txt'\n",
      "The output has been saved to 'steps.txt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 14:57:41,996 - INFO - The converted code is saved in spark_code\\Process one table folder\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the hop order and steps file, the sequence of operations is as follows:\n",
      "\n",
      "1. Number of rows in ${TABLENAME}\n",
      "2. rows-${TABLENAME}.txt\n",
      "\n",
      "Here is the corresponding Pyspark code:\n",
      "\n",
      "```python\n",
      "# Step 1: Number of rows in ${TABLENAME}\n",
      "from pyspark.sql import SparkSession\n",
      "\n",
      "spark = SparkSession.builder.appName(\"CountRows\").getOrCreate()\n",
      "\n",
      "# Assuming that the table is already loaded into a DataFrame named df\n",
      "# Replace 'df' with the actual DataFrame variable\n",
      "df = spark.table(\"TABLENAME\") # Replace 'TABLENAME' with the actual table name\n",
      "count = df.count()\n",
      "\n",
      "# Step 2: rows-${TABLENAME}.txt\n",
      "# Writing the count to a text file\n",
      "with open(\"/tmp/rows-TABLENAME.txt\", \"w\") as file: # Replace 'TABLENAME' with the actual table name\n",
      "    file.write(str(count))\n",
      "```\n",
      "\n",
      "Please replace 'TABLENAME' with the actual table name in your database. Also, ensure that the DataFrame 'df' is pointing to the correct table data.\n",
      "Copied 'hop_order.txt' to 'spark_code\\Process one table'.\n",
      "Copied 'steps.txt' to 'spark_code\\Process one table'.\n",
      "Copied 'pyspark_code.txt' to 'spark_code\\Process one table'.\n"
     ]
    }
   ],
   "source": [
    "def process_directory(directory_path):\n",
    "    # Iterate over all files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        # Check if it's a file and not a directory\n",
    "        if os.path.isfile(file_path):\n",
    "            # Process the file based on its extension\n",
    "            if file_path.endswith('.ktr'):\n",
    "                print('file_path is', file_path)\n",
    "                file_name = os.path.basename(file_path)\n",
    "                folder_name = os.path.splitext(file_name)[0]\n",
    "                process_ktr(file_path, folder_name)\n",
    "\n",
    "# Start the processing with the main directory\n",
    "main_directory_path = r'C:\\Multiple_KTR_Updated\\KJB_and_KTR_updated\\simplepentaho'  # Replace with the path to your directory\n",
    "process_directory(main_directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted: C:\\Multiple_KTR_Updated\\KJB_and_KTR_updated\\spark_code\\Process one table\\pyspark_code.txt to C:\\Multiple_KTR_Updated\\KJB_and_KTR_updated\\spark_code\\Process one table\\pyspark_code.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def convert_txt_to_py(directory):\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file == 'pyspark_code.txt':\n",
    "                txt_file_path = os.path.join(root, file)\n",
    "                py_file_path = os.path.join(root, 'pyspark_code.py')\n",
    "                \n",
    "                try:\n",
    "                    # Read the content of the txt file\n",
    "                    with open(txt_file_path, 'r') as txt_file:\n",
    "                        lines = txt_file.readlines()\n",
    "\n",
    "                    # Write the content to the py file, with each line commented\n",
    "                    with open(py_file_path, 'w') as py_file:\n",
    "                        py_file.write(\"# This file was converted from a .txt file\\n\\n\")\n",
    "                        for line in lines:\n",
    "                            py_file.write(f\"# {line}\")\n",
    "                    \n",
    "                    print(f\"Converted: {txt_file_path} to {py_file_path}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred while converting {txt_file_path}: {e}\")\n",
    "\n",
    "# Example usage\n",
    "directory = r'C:\\Multiple_KTR_Updated\\KJB_and_KTR_updated\\spark_code'\n",
    "convert_txt_to_py(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
